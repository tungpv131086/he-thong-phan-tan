CHÆ¯Æ NG 2 - CÃ‚U 5
Äá» bÃ i:
Trong má»™t máº¡ng P2P khÃ´ng cáº¥u trÃºc, má»™t nÃºt cáº§n tÃ¬m kiáº¿m dá»¯ liá»‡u hiáº¿m (rare data). HÃ£y Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p random walk Ä‘á»ƒ mÃ´ táº£ cÃ¡ch tÃ¬m kiáº¿m dá»¯ liá»‡u nÃ y. Äá» xuáº¥t vÃ  giáº£i thÃ­ch cÃ¡ch cáº£i tiáº¿n (vÃ­ dá»¥: khá»Ÿi Ä‘á»™ng nhiá»u random walks Ä‘á»“ng thá»i) Ä‘á»ƒ giáº£m thá»i gian tÃ¬m tháº¥y dá»¯ liá»‡u, vÃ  phÃ¢n tÃ­ch sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a thá»i gian tÃ¬m kiáº¿m vÃ  lÆ°u lÆ°á»£ng máº¡ng.

BÃ€I GIáº¢I:
Pháº§n 1: Kiáº¿n thá»©c ná»n táº£ng vá» Random Walk
A. Random Walk lÃ  gÃ¬?
Äá»‹nh nghÄ©a:
Random Walk lÃ  thuáº­t toÃ¡n tÃ¬m kiáº¿m trong máº¡ng P2P khÃ´ng cáº¥u trÃºc, trong Ä‘Ã³ query message "Ä‘i bá»™ ngáº«u nhiÃªn" tá»« node nÃ y sang node khÃ¡c, thay vÃ¬ broadcast nhÆ° Flooding.
Äáº·c Ä‘iá»ƒm:

Má»—i bÆ°á»›c chá»n 1 neighbor ngáº«u nhiÃªn Ä‘á»ƒ forward
Tiáº¿p tá»¥c cho Ä‘áº¿n khi tÃ¬m tháº¥y hoáº·c Ä‘áº¡t giá»›i háº¡n (max hops)
Giáº£m drastically sá»‘ messages so vá»›i flooding

So sÃ¡nh vá»›i Flooding:
FLOODING (TTL=3):                 RANDOM WALK (max_hops=10):
       [S]                                [S]
      / | \                                |
    [A][B][C]                            [A]
   /|\ |\ |\                              |
  [...100+ nodes...]                    [D]
                                          |
Messages: ~1000+                        [H] â† Found!
                                          
                                    Messages: 10

B. Táº¡i sao Random Walk phÃ¹ há»£p vá»›i rare data?
Váº¥n Ä‘á» vá»›i rare data:
Rare data = Dá»¯ liá»‡u cÃ³ replication ratio tháº¥p
VÃ­ dá»¥: File chá»‰ cÃ³ á»Ÿ 0.01% nodes trong máº¡ng

Vá»›i Flooding (TTL=3):
- Coverage: 8% máº¡ng (800/10,000 nodes)
- Probability tÃ¬m tháº¥y: 1 - (1-0.0001)^800 â‰ˆ 7.7%
- Chi phÃ­: 1,110 messages
â†’ Vá»«a tá»‘n kÃ©m vá»«a khÃ´ng hiá»‡u quáº£!
Random Walk advantages:
âœ… Chi phÃ­ tháº¥p: O(k) messages vá»›i k = max_hops
âœ… CÃ³ thá»ƒ kÃ©o dÃ i Ä‘á»ƒ tÄƒng coverage (k = 100, 1000...)
âœ… KhÃ´ng gÃ¢y congestion
âœ… ThÃ­ch há»£p cho rare data cáº§n tÃ¬m kiáº¿m sÃ¢u

Pháº§n 2: MÃ´ táº£ chi tiáº¿t Random Walk cÆ¡ báº£n
Giáº£ Ä‘á»‹nh:
- Máº¡ng P2P: 10,000 nodes
- Rare file: "rare_book.pdf" cÃ³ á»Ÿ 10 nodes (0.1% replication)
- Node S (Source) cáº§n tÃ¬m file
- Max hops: 100
Topology máº¡ng:
    [S] â”€â”€â”€â”€ [A] â”€â”€â”€â”€ [D] â”€â”€â”€â”€ [G]
     |        |        |        |
    [B] â”€â”€â”€â”€ [C] â”€â”€â”€â”€ [E] â”€â”€â”€â”€ [H]
     |        |        |        |
    [...]â”€â”€[...]â”€â”€[...]â”€â”€[TargetğŸ¯]

THUáº¬T TOÃN RANDOM WALK CÆ  Báº¢N:
pythonclass RandomWalkSearch:
    def __init__(self, max_hops=100):
        self.max_hops = max_hops
        self.visited_nodes = set()
    
    def search(self, filename, source_node):
        """
        Thá»±c hiá»‡n random walk search
        """
        current_node = source_node
        hops = 0
        path = [source_node]
        
        while hops < self.max_hops:
            # BÆ°á»›c 1: Kiá»ƒm tra node hiá»‡n táº¡i
            if current_node.has_file(filename):
                return {
                    'found': True,
                    'node': current_node,
                    'hops': hops,
                    'path': path
                }
            
            # BÆ°á»›c 2: ÄÃ¡nh dáº¥u Ä‘Ã£ visit (trÃ¡nh loop)
            self.visited_nodes.add(current_node.id)
            
            # BÆ°á»›c 3: Chá»n neighbor ngáº«u nhiÃªn
            neighbors = current_node.get_neighbors()
            
            # Filter: loáº¡i bá» nodes Ä‘Ã£ visit (optional)
            unvisited = [n for n in neighbors 
                        if n.id not in self.visited_nodes]
            
            if not unvisited:
                # Deadend: Táº¥t cáº£ neighbors Ä‘Ã£ visit
                # Option 1: Backtrack
                # Option 2: Chá»n random tá»« táº¥t cáº£ neighbors
                candidates = neighbors
            else:
                candidates = unvisited
            
            # BÆ°á»›c 4: Random selection
            next_node = random.choice(candidates)
            
            # BÆ°á»›c 5: Di chuyá»ƒn Ä‘áº¿n node tiáº¿p theo
            current_node = next_node
            path.append(current_node)
            hops += 1
        
        # KhÃ´ng tÃ¬m tháº¥y sau max_hops
        return {
            'found': False,
            'hops': hops,
            'path': path
        }
```

---

**CHI TIáº¾T CÃC BÆ¯á»šC:**

**BÆ°á»›c khá»Ÿi Ä‘áº§u (Hop 0):**
```
Current Node: S
Action: Check local storage
Result: File khÃ´ng cÃ³
Neighbors: [A, B]
Random selection: A (50% probability)
```

**Hop 1:**
```
Current Node: A
Visited: {S}
Check: File khÃ´ng cÃ³
Neighbors: [S, C, D] 
Unvisited neighbors: [C, D] (loáº¡i S)
Random selection: D (50% probability)
```

**Hop 2:**
```
Current Node: D
Visited: {S, A}
Check: File khÃ´ng cÃ³
Neighbors: [A, E, G]
Unvisited: [E, G]
Random selection: E (50% probability)
```

**Hop 3-99:**
```
Continue random walk...
Node path: S â†’ A â†’ D â†’ E â†’ H â†’ K â†’ ... (random)
Each hop: 1 message
Total messages so far: 99
```

**Hop 100:**
```
Current Node: X
Check: File CÃ“ á»Ÿ Ä‘Ã¢y! ğŸ¯
Return: {
    found: True,
    node: X,
    hops: 100,
    path: [S, A, D, E, ..., X]
}
```

---

**VÃ­ dá»¥ path cá»¥ thá»ƒ:**
```
Random Walk Path (100 hops):
S â†’ A â†’ D â†’ E â†’ H â†’ K â†’ L â†’ P â†’ Q â†’ R
  â†’ T â†’ W â†’ X â†’ Y â†’ Z â†’ M â†’ N â†’ O â†’ S (back to S!)
  â†’ B â†’ C â†’ F â†’ I â†’ J â†’ ... â†’ TargetğŸ¯

Visualization:
    Start
      â†“
    [S]â”€â”€â”€â”€[A]â”€â”€â”€â”€[D]
     â†“      â†“      â†“
    [B]â”€â”€â”€â”€[C]â”€â”€â”€â”€[E]
            â†“      â†“
          [F]    [H]â”€â”€â”€â”€[K]
                  â†“      â†“
                [J]    [L]â”€â”€â”€â”€â†’ ... â†’ [TargetğŸ¯]
```

**Thá»‘ng kÃª:**
```
Total hops: 100
Messages sent: 100
Nodes visited: 100 (hoáº·c Ã­t hÆ¡n náº¿u revisit)
Success: YES (tÃ¬m tháº¥y)
```

---

**PhÃ¢n tÃ­ch hiá»‡u quáº£:**

**Coverage cá»§a Random Walk:**
```
Vá»›i max_hops = k:
- Best case: Visit k unique nodes
- Worst case: Visit < k nodes (do loops)
- Expected: ~0.7k unique nodes (vá»›i loops)

So vá»›i Flooding (TTL=3):
- Flooding: 800 nodes, 1,110 messages
- Random Walk (k=100): 70-100 nodes, 100 messages

â†’ Random Walk: Ãt messages hÆ¡n 11x
â†’ NhÆ°ng coverage tháº¥p hÆ¡n 8x
```

**Probability tÃ¬m tháº¥y rare data:**
```
Giáº£ sá»­ replication ratio r = 0.001 (0.1%)
Total nodes N = 10,000
Nodes cÃ³ file = 10

Vá»›i max_hops = k:
Prob(found) â‰ˆ 1 - (1 - r)^k

k = 100:  P â‰ˆ 9.5%
k = 500:  P â‰ˆ 39%
k = 1000: P â‰ˆ 63%
k = 5000: P â‰ˆ 99.3%

â†’ Cáº§n max_hops ráº¥t lá»›n cho rare data!

Pháº§n 3: Cáº£i tiáº¿n - Multiple Random Walks
A. Parallel Random Walks (Äi bá»™ song song)
Ã tÆ°á»Ÿng:
Thay vÃ¬ 1 walker, khá»Ÿi Ä‘á»™ng nhiá»u walkers Ä‘á»“ng thá»i tá»« source node.
Thuáº­t toÃ¡n:
pythonclass MultipleRandomWalks:
    def __init__(self, num_walkers=5, max_hops_per_walker=200):
        self.num_walkers = num_walkers
        self.max_hops_per_walker = max_hops_per_walker
    
    def search(self, filename, source_node):
        """
        Khá»Ÿi Ä‘á»™ng nhiá»u random walks song song
        """
        walkers = []
        
        # Khá»Ÿi táº¡o multiple walkers
        for i in range(self.num_walkers):
            walker = RandomWalker(
                walker_id=i,
                max_hops=self.max_hops_per_walker
            )
            walkers.append(walker)
        
        # Execute parallel walks
        results = parallel_execute([
            walker.walk(filename, source_node)
            for walker in walkers
        ])
        
        # Aggregate results
        for result in results:
            if result['found']:
                return result  # Tráº£ vá» walker Ä‘áº§u tiÃªn tÃ¬m tháº¥y
        
        return {'found': False}
```

**Visualization:**
```
                Source Node [S]
                     |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |            |            |
    Walker 1     Walker 2     Walker 3
        |            |            |
       [A]         [B]          [C]
        |            |            |
       [D]         [E]          [F]
        |            |            |
       [G]       [TargetğŸ¯]     [H]
        |                         |
       ...                       ...

Walker 2 finds target at hop 3!
Other walkers terminate immediately.
```

---

**BÆ¯á»šC CHI TIáº¾T:**

**Initialization (t=0):**
```
Source: Node S
Launch 5 walkers: W1, W2, W3, W4, W5

W1 â†’ neighbor A
W2 â†’ neighbor B
W3 â†’ neighbor B (cÃ³ thá»ƒ trÃ¹ng)
W4 â†’ neighbor A
W5 â†’ neighbor C
```

**Round 1 (each walker hops once):**
```
W1: S â†’ A â†’ D     (2 hops, 2 messages)
W2: S â†’ B â†’ E     (2 hops, 2 messages)
W3: S â†’ B â†’ F     (2 hops, 2 messages)
W4: S â†’ A â†’ G     (2 hops, 2 messages)
W5: S â†’ C â†’ H     (2 hops, 2 messages)

Total: 10 messages
```

**Round 2:**
```
W1: ... â†’ D â†’ I
W2: ... â†’ E â†’ TargetğŸ¯ (FOUND!)

â†’ Broadcast termination signal to all walkers
â†’ W1, W3, W4, W5 stop immediately
```

**Result:**
```
Success: YES
Winner: Walker 2
Total hops: 3 (S â†’ B â†’ E â†’ Target)
Total messages: ~15 (all walkers combined before termination)
Time: 3 rounds

B. Cáº£i tiáº¿n: Adaptive Walker Strategy
1. Diversified initial directions:
pythondef launch_diverse_walkers(source_node, num_walkers):
    """
    Äáº£m báº£o walkers Ä‘i cÃ¡c hÆ°á»›ng khÃ¡c nhau
    """
    neighbors = source_node.get_neighbors()
    
    # Assign má»—i walker má»™t initial neighbor khÃ¡c nhau
    for i in range(num_walkers):
        initial_neighbor = neighbors[i % len(neighbors)]
        walker = Walker(initial_direction=initial_neighbor)
        launch(walker)
```

**Lá»£i Ã­ch:**
```
TrÃ¡nh tÃ¬nh huá»‘ng: 5 walkers cÃ¹ng Ä‘i 1 hÆ°á»›ng
â†’ TÄƒng coverage area
â†’ TÄƒng success probability

2. Check-back mechanism:
pythonclass SmartWalker:
    def walk(self):
        for hop in range(self.max_hops):
            # Random walk
            current_node = self.random_step()
            
            # Äá»‹nh ká»³ check vá»›i source
            if hop % 10 == 0:
                if self.check_if_others_found():
                    return  # Dá»«ng náº¿u walker khÃ¡c Ä‘Ã£ tÃ¬m tháº¥y
```

**Lá»£i Ã­ch:**
```
TrÃ¡nh lÃ£ng phÃ­: Walkers khÃ´ng tÃ¬m kiáº¿m tiáº¿p sau khi Ä‘Ã£ cÃ³ káº¿t quáº£
â†’ Giáº£m overhead messages

3. TTL for walkers:
pythonclass TTLWalker:
    def __init__(self, walker_id, initial_ttl=50):
        self.walker_id = walker_id
        self.ttl = initial_ttl
    
    def walk(self):
        while self.ttl > 0:
            current_node = self.random_step()
            
            if current_node.has_file(target):
                return SUCCESS
            
            self.ttl -= 1  # Decrement
        
        return TIMEOUT
```

**Lá»£i Ã­ch:**
```
Giá»›i háº¡n má»—i walker, trÃ¡nh "Ä‘i mÃ£i khÃ´ng vá»"
â†’ Bounded execution time
â†’ Predictable resource usage

4. Weighted random walk:
pythondef weighted_random_selection(neighbors):
    """
    Chá»n neighbor dá»±a trÃªn metadata (thay vÃ¬ uniform random)
    """
    weights = []
    for neighbor in neighbors:
        weight = calculate_weight(neighbor)
        weights.append(weight)
    
    # Weighted random choice
    return random.choices(neighbors, weights=weights)[0]

def calculate_weight(node):
    """
    Heuristics Ä‘á»ƒ Æ°u tiÃªn nodes cÃ³ kháº£ nÄƒng cao hÆ¡n
    """
    score = 0
    
    # Æ¯u tiÃªn nodes cÃ³ nhiá»u files
    score += node.num_files * 0.5
    
    # Æ¯u tiÃªn nodes cÃ³ degree cao (hub)
    score += len(node.neighbors) * 0.3
    
    # Æ¯u tiÃªn nodes Ã­t Ä‘Æ°á»£c visit
    if node.id not in visited:
        score += 10
    
    return score
```

**Lá»£i Ã­ch:**
```
ThÃ´ng minh hÆ¡n uniform random
â†’ TÄƒng probability tÃ¬m tháº¥y
â†’ Giáº£m expected hops
```

---

#### **Pháº§n 4: PhÃ¢n tÃ­ch Trade-off**

**A. So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p**

**Báº£ng so sÃ¡nh:**

| Method | Messages | Time (hops) | Success Rate | Congestion |
|--------|----------|-------------|--------------|------------|
| **Flooding (TTL=3)** | 1,110 | 3 | 7.7% (rare) | âŒ High |
| **Single Random Walk (k=100)** | 100 | 100 | 9.5% (rare) | âœ… Low |
| **Multiple Walks (5 walkers, k=100)** | 500 | ~20 | 39% (rare) | âš ï¸ Medium |
| **Adaptive Walks (5 walkers)** | 300-400 | ~15 | 45% (rare) | âš ï¸ Medium |

---

**B. Trade-off chi tiáº¿t: Messages vs Time**

**Scenario 1: Single Random Walk**
```
Configuration:
- 1 walker
- max_hops = 1000

Pros:
âœ… Minimal messages: 1,000
âœ… No congestion
âœ… Simple implementation

Cons:
âŒ Slow: 1,000 sequential hops
âŒ Low success rate: ~63% for rare data
âŒ High latency: 1,000 Ã— RTT

Use case: 
- Non-urgent queries
- Bandwidth-constrained networks
- Low-priority searches
```

**Example timeline:**
```
Time: 0s    â†’ Start
Time: 1s    â†’ Hop 100
Time: 10s   â†’ Hop 1000 (Found or Timeout)

Total time: 10 seconds (assuming 10ms per hop)
Total messages: 1,000
```

---

**Scenario 2: Multiple Random Walks (5 walkers)**
```
Configuration:
- 5 walkers
- max_hops per walker = 200

Pros:
âœ… Faster: Parallel execution
âœ… Higher success rate: ~92% for rare data
âœ… Better coverage

Cons:
âŒ More messages: 5 Ã— 200 = 1,000 (worst case)
âš ï¸ Medium congestion (5x single walker)
âŒ More complex coordination

Use case:
- Time-sensitive queries
- High-priority searches
- Acceptable bandwidth overhead
```

**Example timeline:**
```
Time: 0s    â†’ Launch 5 walkers in parallel
Time: 0.1s  â†’ Each walker at hop 10
Time: 0.5s  â†’ Walker 3 finds target at hop 50
            â†’ Terminate all walkers immediately

Total time: 0.5 seconds
Total messages: 5 Ã— 50 = 250 (early termination)
â†’ 20x faster than single walk!
```

---

**Scenario 3: Adaptive Multiple Walks (5 walkers with heuristics)**
```
Configuration:
- 5 walkers with weighted selection
- Diverse initial directions
- Check-back every 10 hops

Pros:
âœ… Fastest: Intelligent routing
âœ… Highest success rate: ~95%
âœ… Efficient termination

Cons:
âŒ Messages: 300-500 (variable)
âŒ Complex implementation
âŒ Requires node metadata

Use case:
- Production systems
- Critical rare data searches
- Acceptable complexity
```

**Example timeline:**
```
Time: 0s    â†’ Launch 5 diverse walkers
Time: 0.05s â†’ Walkers at hop 5
            â†’ Check-back: No result yet
Time: 0.15s â†’ Walker 2 finds at hop 15
            â†’ Broadcast termination
            â†’ Other walkers stop

Total time: 0.15 seconds
Total messages: ~75 (very efficient!)
â†’ 66x faster than single walk!
```

---

**C. Trade-off formula**

**Expected time to find:**
```
Single walker:
E[T_single] = E[hops] Ã— RTT_per_hop
            = (1/p) Ã— RTT
            where p = probability per node

Multiple walkers (k walkers):
E[T_multi] = E[T_single] / k  (approximate)
           = (1/p) Ã— RTT / k

Speedup â‰ˆ k (number of walkers)
```

**Expected messages:**
```
Single walker:
E[M_single] = E[hops] = 1/p

Multiple walkers (without early termination):
E[M_multi] = k Ã— E[hops] = k/p

Multiple walkers (with early termination):
E[M_multi] â‰ˆ k Ã— E[hops_first_success]
           â‰ˆ k Ã— (1/kp)  (approximate)
           â‰ˆ 1/p (same as single!)

â†’ Early termination is critical!
```

**Example calculation:**
```
Given:
- Replication ratio p = 0.001 (0.1%)
- RTT per hop = 10ms
- Number of walkers k = 5

Single walker:
E[T] = (1/0.001) Ã— 10ms = 10,000ms = 10s
E[M] = 1/0.001 = 1,000 messages

Multiple walkers (with early termination):
E[T] = 10s / 5 = 2s
E[M] = 1,000 messages (distributed across 5 walkers)
      â‰ˆ 200 messages (actual, due to early stop)

â†’ Time: 5x faster
â†’ Messages: Similar or better (with early termination)

Pháº§n 5: Äá» xuáº¥t giáº£i phÃ¡p tá»‘i Æ°u
A. Hybrid Approach: k-Random Walks with Adaptive TTL
pythonclass OptimalRareDataSearch:
    def __init__(self):
        self.phase_config = [
            {'walkers': 3, 'ttl_per_walker': 50},   # Phase 1: Quick scan
            {'walkers': 5, 'ttl_per_walker': 100},  # Phase 2: Medium search
            {'walkers': 10, 'ttl_per_walker': 200}  # Phase 3: Deep search
        ]
    
    def search(self, filename, source_node):
        for phase in self.phase_config:
            result = self.execute_phase(
                filename, 
                source_node,
                num_walkers=phase['walkers'],
                ttl=phase['ttl_per_walker']
            )
            
            if result['found']:
                return result
            
            # Äá»£i má»™t chÃºt trÆ°á»›c khi escalate
            sleep(0.5)
        
        return {'found': False}
    
    def execute_phase(self, filename, source, num_walkers, ttl):
        # Launch walkers with diverse directions
        walkers = self.launch_diverse_walkers(source, num_walkers)
        
        # Parallel execution with early termination
        results = parallel_execute_with_termination(walkers, ttl)
        
        return aggregate_results(results)
```

**Æ¯u Ä‘iá»ƒm:**
```
âœ… Escalating search: Báº¯t Ä‘áº§u nháº¹, tÄƒng dáº§n náº¿u cáº§n
âœ… Balance: Time vs Messages
âœ… Adaptive: Dá»«ng sá»›m náº¿u tÃ¬m tháº¥y
```

**Example execution:**
```
Phase 1 (0-0.5s):
â”œâ”€ Launch 3 walkers, TTL=50 each
â”œâ”€ Total messages: â‰¤ 150
â””â”€ Result: Not found

Phase 2 (0.5-1.5s):
â”œâ”€ Launch 5 walkers, TTL=100 each
â”œâ”€ Total messages: â‰¤ 500
â””â”€ Result: FOUND at walker 2, hop 73!
â””â”€ Total actual messages: 3Ã—50 + 5Ã—73 = 515

Total time: 1.5s
Success: YES
Messages: 515 (acceptable)

B. Learning-based approach
pythonclass LearningWalker:
    def __init__(self):
        self.node_success_history = {}  # Track which nodes often have rare files
    
    def weighted_selection(self, neighbors):
        """
        Chá»n neighbor dá»±a trÃªn lá»‹ch sá»­ thÃ nh cÃ´ng
        """
        scores = []
        for neighbor in neighbors:
            # Base score
            score = 1.0
            
            # Bonus náº¿u neighbor tá»«ng cÃ³ rare files
            if neighbor.id in self.node_success_history:
                score += self.node_success_history[neighbor.id] * 5
            
            scores.append(score)
        
        return weighted_random_choice(neighbors, scores)
    
    def update_history(self, path, found_node):
        """
        Sau khi tÃ¬m tháº¥y, update history
        """
        for node in path:
            if node.id not in self.node_success_history:
                self.node_success_history[node.id] = 0
            
            # Nodes gáº§n found_node cÃ³ score cao hÆ¡n
            distance = path_distance(node, found_node)
            self.node_success_history[node.id] += 1.0 / (distance + 1)
```

**Lá»£i Ã­ch:**
```
âœ… Há»c tá»« quÃ¡ khá»©
âœ… Cáº£i thiá»‡n qua thá»i gian
âœ… Táº­n dá»¥ng clustering (rare files thÆ°á»ng cluster)
```

---

#### **Pháº§n 6: TÃ³m táº¯t vÃ  khuyáº¿n nghá»‹**

**So sÃ¡nh tá»•ng quan:**

| Approach | Time | Messages | Success (rare) | Complexity | Best for |
|----------|------|----------|----------------|------------|----------|
| **Flooding** | âœ… Fast (3 hops) | âŒ High (1,110) | âŒ Low (8%) | âš ï¸ Medium | Popular files |
| **Single Random Walk** | âŒ Slow (1,000 hops) | âœ… Low (1,000) | âš ï¸ Medium (63%) | âœ… Simple | Low priority, constrained bandwidth |
| **Multiple Random Walks** | âš ï¸ Medium (200 hops) | âš ï¸ Medium (500) | âœ… High (92%) | âš ï¸ Medium | Balanced approach |
| **Adaptive Multiple Walks** | âœ… Fast (50 hops) | âš ï¸ Medium (300) | âœ… Very High (95%) | âŒ Complex | Production, critical searches |
| **Hybrid Approach** | âœ… Fast (avg 100) | âš ï¸ Medium (400) | âœ… High (90%) | âš ï¸ Medium | General purpose |

---

**Khuyáº¿n nghá»‹ theo use case:**

**1. Rare data, time-sensitive:**
```
âœ… Use: Adaptive Multiple Walks (5-10 walkers)
Configuration:
- 5 walkers initially
- Diverse initial directions
- TTL = 100 per walker
- Check-back every 10 hops
- Weighted selection if possible

Expected:
- Time: 1-2 seconds
- Messages: 300-500
- Success: 90-95%
```

**2. Rare data, bandwidth-constrained:**
```
âœ… Use: Single Random Walk with high TTL
Configuration:
- 1 walker
- TTL = 2,000
- Simple uniform random

Expected:
- Time: 10-20 seconds
- Messages: 1,000-2,000
- Success: 85%
```

**3. Rare data, balanced:**
```
âœ… Use: Hybrid approach (escalating)
Configuration:
- Phase 1: 3 walkers Ã— 50 TTL
- Phase 2: 5 walkers Ã— 100 TTL
- Phase 3: 10 walkers Ã— 200 TTL

Expected:
- Time: 2-5 seconds (average)
- Messages: 300-800 (average)
- Success: 90%
```

---

**Káº¿t luáº­n:**

Äá»‘i vá»›i rare data trong P2P khÃ´ng cáº¥u trÃºc:

1. **Random Walk** lÃ  lá»±a chá»n tá»‘t hÆ¡n **Flooding** vÃ¬:
   - Giáº£m drastically network congestion
   - CÃ³ thá»ƒ tÃ¬m kiáº¿m sÃ¢u vá»›i chi phÃ­ tháº¥p
   - PhÃ¹ há»£p vá»›i rare data (low replication)

2. **Multiple Random Walks** cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ:
   - Time: Giáº£m k láº§n (k = sá»‘ walkers)
   - Success rate: TÄƒng exponentially
   - Messages: Chá»‰ tÄƒng tuyáº¿n tÃ­nh (vá»›i early termination)

3. **Trade-off chÃ­nh:**
```
   More walkers:
   âœ… Faster search
   âœ… Higher success rate
   âŒ More messages
   âŒ More coordination complexity

Sweet spot: 5-10 parallel walkers vá»›i adaptive TTL

Balance tá»‘t nháº¥t giá»¯a time vÃ  messages
Success rate cao (>90%)
Practical implementation