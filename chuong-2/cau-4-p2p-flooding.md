# CÃ¢u 4: P2P Flooding Search vá»›i TTL

> **ChÆ°Æ¡ng:** 2 - Kiáº¿n trÃºc Há»‡ thá»‘ng PhÃ¢n tÃ¡n  
> **Äá»™ khÃ³:** â­â­â­ (Trung bÃ¬nh)  
> **Thá»i gian Ä‘á»c:** ~20 phÃºt

---

## ğŸ“‹ Má»¥c lá»¥c

- [Äá» bÃ i](#Ä‘á»-bÃ i)
- [Pháº§n 1: CÆ¡ cháº¿ Flooding](#pháº§n-1-cÆ¡-cháº¿-flooding)
- [Pháº§n 2: PhÃ¢n tÃ­ch trong máº¡ng máº­t Ä‘á»™ cao](#pháº§n-2-phÃ¢n-tÃ­ch-trong-máº¡ng-máº­t-Ä‘á»™-cao)
- [Pháº§n 3: Trade-offs vÃ  Giáº£i phÃ¡p](#pháº§n-3-trade-offs-vÃ -giáº£i-phÃ¡p)
- [TÃ³m táº¯t](#tÃ³m-táº¯t)

---

## ğŸ“‹ Äá» bÃ i

Trong máº¡ng P2P sá»­ dá»¥ng **flooding** Ä‘á»ƒ tÃ¬m kiáº¿m tÃ i nguyÃªn, má»™t query Ä‘Æ°á»£c gá»­i vá»›i **TTL = 3** (time-to-live).

**Giáº£ sá»­:**
- Má»—i node cÃ³ trung bÃ¬nh **k = 10 neighbors** (degree cao)
- Máº¡ng cÃ³ **N = 10,000 nodes**

**YÃªu cáº§u:**

1. Æ¯á»›c lÆ°á»£ng sá»‘ **nodes** vÃ  **messages** Ä‘Æ°á»£c truyá»n trong quÃ¡ trÃ¬nh flooding
2. PhÃ¢n tÃ­ch **trade-off** giá»¯a:
   - Coverage (Ä‘á»™ phá»§ máº¡ng)
   - Message overhead (lÆ°á»£ng thÃ´ng Ä‘iá»‡p)
3. Äá» xuáº¥t cÃ¡c biá»‡n phÃ¡p giáº£m overhead mÃ  váº«n giá»¯ hiá»‡u quáº£ tÃ¬m kiáº¿m

---

## ğŸ’¡ BÃ i giáº£i

### Pháº§n 1: CÆ¡ cháº¿ Flooding

#### A. Thuáº­t toÃ¡n Flooding cÆ¡ báº£n
```
FLOODING ALGORITHM:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Node initiates query with TTL
2. Broadcast to all neighbors
3. Each neighbor:
   a. Decrements TTL
   b. If TTL > 0 AND not seen before:
      - Forward to all neighbors
   c. If has resource:
      - Send response back
4. Repeat until TTL = 0
```

**Pseudocode:**
```python
class Node:
    def __init__(self, node_id, neighbors):
        self.id = node_id
        self.neighbors = neighbors  # List of connected nodes
        self.seen_queries = set()   # Track processed queries
    
    def search(self, query_id, keyword, ttl, sender=None):
        """
        Flooding search algorithm
        """
        # Check if already processed this query
        if query_id in self.seen_queries:
            return  # Drop duplicate
        
        # Mark as seen
        self.seen_queries.add(query_id)
        
        print(f"Node {self.id}: Received query {query_id}, TTL={ttl}")
        
        # Check if this node has the resource
        if self.has_resource(keyword):
            print(f"Node {self.id}: FOUND! Sending response back")
            self.send_response(query_id, sender)
            return
        
        # If TTL expired, stop
        if ttl <= 0:
            print(f"Node {self.id}: TTL expired, stop")
            return
        
        # Forward to all neighbors (except sender)
        for neighbor in self.neighbors:
            if neighbor != sender:
                neighbor.search(query_id, keyword, ttl - 1, self)
```

#### B. Visualization vá»›i TTL = 3
```
FLOODING PROPAGATION (k=10 neighbors per node):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Level 0 (TTL=3): Starting node
              â—
              â”‚ Query initiated
              â””â”€ Broadcasts to 10 neighbors

Level 1 (TTL=2): First hop
        â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€...â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
        â—     â—     â—         â—     â—  (10 nodes)
        â”‚ Each broadcasts to 9 neighbors
        â”‚ (excluding sender)

Level 2 (TTL=1): Second hop
    â”Œâ”€â”€â”€â”¼â”€â”€â”€â”¬...
    â—   â—   â—  ...              (90 nodes)
    â”‚ Each broadcasts to 9 neighbors

Level 3 (TTL=0): Third hop
  â—â—â—â—â— ...                     (810 nodes)
  â”‚ TTL expired, stop

Total nodes reached: 1 + 10 + 90 + 810 = 911 nodes
```

#### C. TÃ­nh toÃ¡n chÃ­nh xÃ¡c

**Sá»‘ nodes Ä‘Æ°á»£c visit:**
```
Formula: Nodes(TTL) = 1 + k + k(k-1) + k(k-1)Â² + ... + k(k-1)^(TTL-1)

Vá»›i k=10, TTL=3:

Level 0: 1 node (starting node)
Level 1: k = 10 nodes
Level 2: k Ã— (k-1) = 10 Ã— 9 = 90 nodes
Level 3: k Ã— (k-1)Â² = 10 Ã— 81 = 810 nodes

Total: 1 + 10 + 90 + 810 = 911 nodes âœ…

As percentage of network:
911 / 10,000 = 9.11% coverage
```

**Sá»‘ messages Ä‘Æ°á»£c gá»­i:**
```
Messages = Edges traversed

Level 0 â†’ Level 1: 10 messages (to 10 neighbors)
Level 1 â†’ Level 2: 10 Ã— 9 = 90 messages
Level 2 â†’ Level 3: 90 Ã— 9 = 810 messages

Total messages: 10 + 90 + 810 = 910 messages

Alternative formula:
Messages = Nodes - 1 (tree structure)
         = 911 - 1 = 910 âœ…

Note: With duplicates (if not filtered):
Real messages could be 2-3x higher!
```

---

### Pháº§n 2: PhÃ¢n tÃ­ch trong máº¡ng máº­t Ä‘á»™ cao

#### A. Impact of High Degree (k=10)
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        FLOODING IN HIGH-DEGREE NETWORK           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                  â•‘
â•‘  Metric              â”‚ Value      â”‚ Impact       â•‘
â•‘ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•  â•‘
â•‘                                                  â•‘
â•‘  Nodes visited       â”‚    911     â”‚ Good âœ…      â•‘
â•‘  Coverage            â”‚   9.11%    â”‚ Limited âš ï¸   â•‘
â•‘  Messages sent       â”‚    910     â”‚ High âš ï¸      â•‘
â•‘  Duplicate msgs      â”‚  ~1,800    â”‚ Very high âŒ â•‘
â•‘  Network bandwidth   â”‚  ~3.6 MB   â”‚ Expensive âŒ â•‘
â•‘                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Assumptions:
- Message size: 4 KB (query + metadata)
- 910 messages Ã— 4 KB = 3,640 KB â‰ˆ 3.6 MB
- With duplicates: ~7.2 MB per query!
```

#### B. Success Rate Analysis

**Probability of finding resource:**
```python
def success_probability(replication_rate, coverage):
    """
    P(success) = 1 - P(miss all replicas)
               = 1 - (1 - r)^n
    
    r: replication rate (% nodes with resource)
    n: nodes visited
    """
    return 1 - (1 - replication_rate) ** coverage

# Calculate for different replication rates
replication = [0.001, 0.01, 0.1]  # 0.1%, 1%, 10%
nodes_visited = 911

for r in replication:
    p_success = success_probability(r, nodes_visited)
    print(f"Replication {r*100}%: Success rate = {p_success*100:.2f}%")
```

**Results:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      SUCCESS RATE vs REPLICATION              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  Replication â”‚ Nodes   â”‚ Success  â”‚ Comment  â•‘
â•‘  Rate        â”‚ Visited â”‚ Rate     â”‚          â•‘
â•‘ â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â• â•‘
â•‘              â”‚         â”‚          â”‚          â•‘
â•‘  0.01%       â”‚   911   â”‚   9.4%   â”‚ Poor âŒ  â•‘
â•‘  (rare)      â”‚         â”‚          â”‚          â•‘
â•‘              â”‚         â”‚          â”‚          â•‘
â•‘  0.1%        â”‚   911   â”‚  60.0%   â”‚ OK âš ï¸    â•‘
â•‘  (uncommon)  â”‚         â”‚          â”‚          â•‘
â•‘              â”‚         â”‚          â”‚          â•‘
â•‘  1%          â”‚   911   â”‚  99.99%  â”‚ Good âœ…  â•‘
â•‘  (common)    â”‚         â”‚          â”‚          â•‘
â•‘              â”‚         â”‚          â”‚          â•‘
â•‘  10%         â”‚   911   â”‚ >99.99%  â”‚ Overkill â•‘
â•‘  (popular)   â”‚         â”‚          â”‚          â•‘
â•‘              â”‚         â”‚          â”‚          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Conclusion:
- For popular files (r â‰¥ 1%): High success âœ…
- For rare files (r < 0.1%): Poor success âŒ
- TTL=3 insufficient for rare content!
```

#### C. Network Congestion
```
Scenario: 100 concurrent queries

Per query: 910 messages
Total: 100 Ã— 910 = 91,000 messages

If each message = 4 KB:
Bandwidth = 91,000 Ã— 4 KB = 364 MB
Time span = ~1 second
Rate = 364 MB/s = 2.9 Gbps ğŸ”¥

Impact:
âŒ Network saturation
âŒ Hub nodes overloaded
âŒ High latency for all traffic
âŒ Packet loss likely

Hub node (high degree):
- Receives queries from ALL neighbors
- Must forward to ALL neighbors
- Processing: 10 incoming Ã— 9 outgoing = 90 messages
- If 100 concurrent queries: 9,000 messages/sec âŒ
```

---

### Pháº§n 3: Trade-offs vÃ  Giáº£i phÃ¡p

#### A. TTL Trade-off Analysis
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           TTL vs COVERAGE vs OVERHEAD             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                   â•‘
â•‘  TTL â”‚ Nodes    â”‚ Messages  â”‚ Coverage â”‚ BW      â•‘
â•‘      â”‚ Visited  â”‚           â”‚          â”‚         â•‘
â•‘ â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â• â•‘
â•‘      â”‚          â”‚           â”‚          â”‚         â•‘
â•‘   1  â”‚      11  â”‚       10  â”‚   0.1%   â”‚  40 KB  â•‘
â•‘   2  â”‚     101  â”‚      100  â”‚   1.0%   â”‚ 400 KB  â•‘
â•‘   3  â”‚     911  â”‚      910  â”‚   9.1%   â”‚ 3.6 MB  â•‘
â•‘   4  â”‚   8,191  â”‚    8,190  â”‚  81.9%   â”‚  32 MB  â•‘
â•‘   5  â”‚  73,711  â”‚   73,710  â”‚ 737%â—   â”‚ 287 MB  â•‘
â•‘      â”‚          â”‚           â”‚ (overlap)â”‚         â•‘
â•‘                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Observations:
- TTL 3â†’4: Coverage 9Ã— but overhead 9Ã— âš ï¸
- TTL 4â†’5: Exceeds network size (duplicates)
- Sweet spot: TTL = 3-4 for N=10K
```

**Mathematical relationship:**
```
Messages(TTL) â‰ˆ k Ã— (k-1)^TTL

For k=10:
TTL=1: 10
TTL=2: 10 Ã— 9Â¹ = 90
TTL=3: 10 Ã— 9Â² = 810
TTL=4: 10 Ã— 9Â³ = 7,290

Exponential growth! ğŸš€
```

#### B. Biá»‡n phÃ¡p giáº£m overhead

**1. Expanding Ring Search**
```
Strategy: Start with low TTL, increase if not found

Step 1: Search with TTL=1
        â†“ Not found
Step 2: Search with TTL=2
        â†“ Not found
Step 3: Search with TTL=3
        â†“ Found! âœ…

Total messages:
- If found at TTL=1: 10 messages âœ…
- If found at TTL=2: 10 + 90 = 100 messages âœ…
- If found at TTL=3: 10 + 90 + 810 = 910 messages

Average case (for popular files):
Much better than always using TTL=3! âœ…

Code:
def expanding_ring_search(keyword):
    for ttl in [1, 2, 3, 5, 7]:  # Progressive TTLs
        result = flood_search(keyword, ttl)
        if result:
            return result
        time.sleep(0.5)  # Wait before retry
    return None  # Not found
```

**Savings:**
```
Without expanding ring:
- Always TTL=3: 910 messages
- 100 queries: 91,000 messages

With expanding ring:
- 80% found at TTL=1: 80 Ã— 10 = 800
- 15% found at TTL=2: 15 Ã— 100 = 1,500
- 5% found at TTL=3: 5 Ã— 910 = 4,550
- Total: 6,850 messages âœ…

Savings: 91,000 - 6,850 = 84,150 (92% reduction!) ğŸ‰
```

**2. Random Walk (Alternative approach)**
```
Instead of flooding to ALL neighbors:
â†’ Forward to ONE random neighbor

Algorithm:
1. Pick random neighbor
2. Forward query (TTL--)
3. If not found, try another random walk

Comparison:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              Flooding   Random Walk
Messages:        910          100
Coverage:       9.1%          1%
Success (r=1%): 99.9%        63%

For rare files (r=0.1%):
Multiple random walks (5Ã—):
- Messages: 5 Ã— 100 = 500 âœ…
- Coverage: 5%
- Success: 95% âœ…
- Still 2Ã— better than flooding!
```

**3. Bloom Filter-based Duplicate Detection**
```python
from bloom_filter import BloomFilter

class Node:
    def __init__(self):
        # Bloom filter for seen query IDs
        self.bloom = BloomFilter(max_elements=10000, error_rate=0.01)
    
    def search(self, query_id, keyword, ttl):
        # Check if already seen (fast!)
        if query_id in self.bloom:
            return  # Likely duplicate, drop
        
        # Add to bloom filter
        self.bloom.add(query_id)
        
        # Process query...
        if ttl > 0:
            for neighbor in self.neighbors:
                neighbor.search(query_id, keyword, ttl-1)

Benefits:
âœ… Space: 12 KB vs 400 KB (hash set)
âœ… Speed: O(1) lookup
âœ… Reduces duplicate messages by ~70%
âš ï¸ Small false positive rate (1%)
```

**4. Super-Peer Architecture**
```
Hybrid P2P: Combine flooding with centralized index

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SUPER PEERS (High capacity)    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ SP1  â”‚â”€â”€â”‚ SP2  â”‚â”€â”€â”‚ SP3  â”‚         â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚         â”‚         â”‚
   â”Œâ”€â”€â”´â”€â”€â”   â”Œâ”€â”´â”€â”€â”   â”Œâ”€â”€â”´â”€â”€â”
   â”‚ P1  â”‚   â”‚ P2 â”‚   â”‚ P3  â”‚  Regular peers
   â”‚ P4  â”‚   â”‚ P5 â”‚   â”‚ P6  â”‚
   â”‚ P7  â”‚   â”‚ P8 â”‚   â”‚ P9  â”‚
   â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜

Search process:
1. Query sent to super-peer
2. Super-peer floods to other super-peers (small network)
3. Each super-peer checks its local peers

Messages:
- Flooding among 100 super-peers: ~1,000 messages
- Local search: ~10 messages per SP
- Total: ~2,000 messages âœ…
- vs 91,000 in pure flooding! (95% reduction ğŸ‰)
```

**5. TTL Adaptation based on Query Type**
```python
def adaptive_ttl(query_type, keyword):
    """
    Adjust TTL based on expected replication
    """
    if query_type == "popular":
        # Popular files (music, movies)
        return 1  # Found quickly âœ…
    
    elif query_type == "common":
        # Moderately replicated
        return 2
    
    elif query_type == "rare":
        # Rare or specific files
        return 5  # Need wider search
    
    elif query_type == "keyword_search":
        # Broad search
        return 3
    
    else:
        return 3  # Default

# Machine learning approach
def predict_ttl(keyword, history):
    """
    Learn optimal TTL from past queries
    """
    # Features: keyword length, frequency, past success
    # Use random forest or neural network
    # Output: Predicted optimal TTL
    pass
```

---

## ğŸ“Š TÃ³m táº¯t

### Key Points

- âœ… **Flooding with TTL=3**: 911 nodes, 910 messages
- âœ… **Coverage**: 9.11% of 10K-node network
- âœ… **Success rate**: >99% for popular files (râ‰¥1%)
- âš ï¸ **Overhead**: Exponential growth (9x per TTL)
- âŒ **Rare files**: Poor success rate (9% for r=0.01%)

### Trade-offs
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            FLOODING TRADE-OFFS                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  Increase TTL:                                â•‘
â•‘  âœ… Higher coverage                           â•‘
â•‘  âœ… Better for rare files                     â•‘
â•‘  âŒ Exponentially more messages               â•‘
â•‘  âŒ Network congestion                        â•‘
â•‘                                               â•‘
â•‘  Decrease TTL:                                â•‘
â•‘  âœ… Lower overhead                            â•‘
â•‘  âœ… Less congestion                           â•‘
â•‘  âŒ Lower coverage                            â•‘
â•‘  âŒ Miss rare files                           â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Khuyáº¿n nghá»‹

**Cho máº¡ng k=10, N=10K:**

| File Type | Strategy | TTL | Messages | Success |
|-----------|----------|-----|----------|---------|
| Popular (r>1%) | Expanding ring | 1â†’2â†’3 | ~100 âœ… | 99%+ |
| Common (r~0.1%) | Fixed TTL | 3 | 910 âš ï¸ | 60% |
| Rare (r<0.01%) | Random walk Ã— 5 | 100 each | 500 âœ… | 95% |
| Critical | Super-peer | 2 (SPs) | ~2,000 | 99% |

---

## ğŸ”— TÃ i liá»‡u tham kháº£o

### Papers
- **"A Measurement Study of Peer-to-Peer File Sharing Systems"** - Saroiu et al., 2002
- **"Search in Power-Law Networks"** - Adamic et al., 2001

### Systems
- **Gnutella**: Early P2P using flooding
- **Kazaa**: Super-peer architecture
- **BitTorrent**: DHT-based (no flooding)

---

## ğŸ§­ Navigation

**[â¬…ï¸ CÃ¢u 3: Chord DHT](./cau-3-chord-dht.md)** | **[ğŸ“š Quay láº¡i ChÆ°Æ¡ng 2](./README.md)** | **[â¡ï¸ CÃ¢u 5: Random Walk](./cau-5-random-walk.md)**

---

*Cáº­p nháº­t láº§n cuá»‘i: 11/12/2025*