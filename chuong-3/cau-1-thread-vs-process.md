# CÃ¢u 1: Thread vs Process - Context Switching

> **ChÆ°Æ¡ng:** 3 - Tiáº¿n trÃ¬nh vÃ  áº¢o hÃ³a  
> **Äá»™ khÃ³:** â­â­â­ (Trung bÃ¬nh)  
> **Thá»i gian Ä‘á»c:** ~20 phÃºt

---

## ğŸ“‹ Má»¥c lá»¥c

- [Äá» bÃ i](#Ä‘á»-bÃ i)
- [Pháº§n 1: Äá»‹nh nghÄ©a Thread vÃ  Process](#pháº§n-1-Ä‘á»‹nh-nghÄ©a-thread-vÃ -process)
- [Pháº§n 2: Context Switch Analysis](#pháº§n-2-context-switch-analysis)
- [Pháº§n 3: Multicore Performance](#pháº§n-3-multicore-performance)
- [Pháº§n 4: Use Cases](#pháº§n-4-use-cases)
- [TÃ³m táº¯t](#tÃ³m-táº¯t)

---

## ğŸ“‹ Äá» bÃ i

Má»™t há»‡ thá»‘ng cÃ³ hai mÃ´ hÃ¬nh thá»±c thi:

**MÃ´ hÃ¬nh A: Multi-process**
- Má»—i request Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi má»™t **process** riÃªng biá»‡t
- Context switch giá»¯a processes: **50 Âµs**

**MÃ´ hÃ¬nh B: Multi-threaded**
- Má»—i request Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi má»™t **thread** trong cÃ¹ng process
- Context switch giá»¯a threads: **5 Âµs**

**YÃªu cáº§u:**

1. Giáº£i thÃ­ch sá»± khÃ¡c biá»‡t giá»¯a **thread** vÃ  **process** vá»:
   - Memory space
   - Resource sharing
   - Communication overhead

2. TÃ­nh toÃ¡n vÃ  so sÃ¡nh **overhead** cá»§a context switching:
   - Vá»›i 10,000 switches/second
   - Impact lÃªn throughput

3. PhÃ¢n tÃ­ch khi nÃ o nÃªn dÃ¹ng **multi-process** vs **multi-threaded** trong há»‡ thá»‘ng phÃ¢n tÃ¡n, Ä‘áº·c biá»‡t trÃªn **multicore processors**

---

## ğŸ’¡ BÃ i giáº£i

### Pháº§n 1: Äá»‹nh nghÄ©a Thread vÃ  Process

#### A. Process (Tiáº¿n trÃ¬nh)
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              PROCESS STRUCTURE                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚   Process Control Block (PCB)           â”‚ â•‘
â•‘  â”‚   - Process ID (PID)                    â”‚ â•‘
â•‘  â”‚   - Program counter                     â”‚ â•‘
â•‘  â”‚   - CPU registers                       â”‚ â•‘
â•‘  â”‚   - Memory management info              â”‚ â•‘
â•‘  â”‚   - I/O status                          â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚   MEMORY SPACE (isolated)               â”‚ â•‘
â•‘  â”‚                                         â”‚ â•‘
â•‘  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚   â”‚  Stack (local variables)        â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Heap (dynamic allocation)      â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Data (global variables)        â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Code (executable instructions) â”‚  â”‚ â•‘
â•‘  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚   RESOURCES (exclusive)                 â”‚ â•‘
â•‘  â”‚   - File descriptors                    â”‚ â•‘
â•‘  â”‚   - Network sockets                     â”‚ â•‘
â•‘  â”‚   - Locks                               â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Characteristics:
âœ… Isolated memory (cannot access other process memory)
âœ… Independent resources
âœ… Heavyweight (large overhead to create)
âœ… Safe (crash doesn't affect other processes)
âš ï¸ Slow communication (IPC required)
```

#### B. Thread (Luá»“ng)
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           MULTI-THREADED PROCESS              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  SHARED RESOURCES:                            â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚   Process Control Block (PCB)           â”‚ â•‘
â•‘  â”‚   - Process ID (shared)                 â”‚ â•‘
â•‘  â”‚   - Memory management (shared)          â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚   SHARED MEMORY SPACE                   â”‚ â•‘
â•‘  â”‚                                         â”‚ â•‘
â•‘  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â•‘
â•‘  â”‚   â”‚  Stack Thread 1 (private)       â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Stack Thread 2 (private)       â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Stack Thread 3 (private)       â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Heap (SHARED) âœ…               â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Data (SHARED) âœ…               â”‚  â”‚ â•‘
â•‘  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â•‘
â•‘  â”‚   â”‚  Code (SHARED) âœ…               â”‚  â”‚ â•‘
â•‘  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                               â•‘
â•‘  PER-THREAD STATE:                            â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â•‘
â•‘  â”‚ Thread 1  â”‚ Thread 2  â”‚ Thread 3  â”‚       â•‘
â•‘  â”‚ - TID     â”‚ - TID     â”‚ - TID     â”‚       â•‘
â•‘  â”‚ - PC      â”‚ - PC      â”‚ - PC      â”‚       â•‘
â•‘  â”‚ - Regs    â”‚ - Regs    â”‚ - Regs    â”‚       â•‘
â•‘  â”‚ - Stack   â”‚ - Stack   â”‚ - Stack   â”‚       â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Characteristics:
âœ… Shared memory (fast communication)
âœ… Shared resources
âœ… Lightweight (low overhead to create)
âš ï¸ Unsafe (one thread crash can kill process)
âš ï¸ Need synchronization (race conditions)
```

#### C. Key Differences
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        PROCESS vs THREAD COMPARISON               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                   â•‘
â•‘  Aspect          â”‚ Process         â”‚ Thread       â•‘
â•‘ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â• â•‘
â•‘                                                   â•‘
â•‘  Memory Space    â”‚ Separate âœ…     â”‚ Shared âœ…    â•‘
â•‘                  â”‚ 4GB+ per proc   â”‚ 2MB+ total   â•‘
â•‘                                                   â•‘
â•‘  Creation Time   â”‚ 1-5 ms âš ï¸       â”‚ 50-100 Âµs âœ… â•‘
â•‘                                                   â•‘
â•‘  Context Switch  â”‚ 50 Âµs âš ï¸        â”‚ 5 Âµs âœ…      â•‘
â•‘                                                   â•‘
â•‘  Communication   â”‚ IPC (pipe, MQ)  â”‚ Shared mem   â•‘
â•‘                  â”‚ Slow âš ï¸         â”‚ Fast âœ…      â•‘
â•‘                                                   â•‘
â•‘  Overhead        â”‚ High âš ï¸         â”‚ Low âœ…       â•‘
â•‘                  â”‚ (TLB flush)     â”‚ (cache hit)  â•‘
â•‘                                                   â•‘
â•‘  Isolation       â”‚ Strong âœ…       â”‚ Weak âš ï¸      â•‘
â•‘                  â”‚ (protected)     â”‚ (shared)     â•‘
â•‘                                                   â•‘
â•‘  Failure Impact  â”‚ Isolated âœ…     â”‚ Cascading âŒ â•‘
â•‘                                                   â•‘
â•‘  Scalability     â”‚ Limited âš ï¸      â”‚ Better âœ…    â•‘
â•‘                  â”‚ (OS limits)     â”‚ (thousands)  â•‘
â•‘                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

### Pháº§n 2: Context Switch Analysis

#### A. Context Switch Cost Breakdown

**Process Context Switch (50 Âµs):**
```
PROCESS CONTEXT SWITCH:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Save current process state (5 Âµs)
   â”œâ”€ Save CPU registers
   â”œâ”€ Save program counter
   â”œâ”€ Save stack pointer
   â””â”€ Update PCB

2. Select next process (2 Âµs)
   â”œâ”€ Scheduler decision
   â””â”€ Priority calculation

3. Memory management switch (30 Âµs) âš ï¸
   â”œâ”€ Save current page table
   â”œâ”€ Load new page table
   â”œâ”€ TLB flush (Translation Lookaside Buffer)
   â””â”€ Cache pollution (data no longer relevant)

4. Load next process state (8 Âµs)
   â”œâ”€ Restore CPU registers
   â”œâ”€ Restore program counter
   â”œâ”€ Update CPU mode
   â””â”€ Resume execution

5. Overhead (5 Âµs)
   â”œâ”€ Kernel transition
   â””â”€ Interrupt handling

Total: ~50 Âµs âš ï¸

Main cost: Memory management (60% of time) âŒ
```

**Thread Context Switch (5 Âµs):**
```
THREAD CONTEXT SWITCH:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Save current thread state (1 Âµs)
   â”œâ”€ Save CPU registers
   â”œâ”€ Save program counter
   â””â”€ Save stack pointer

2. Select next thread (0.5 Âµs)
   â”œâ”€ Scheduler decision (simpler)
   â””â”€ Priority calculation

3. Memory management (0 Âµs) âœ…
   â”œâ”€ NO page table switch (same process!)
   â”œâ”€ NO TLB flush
   â””â”€ Cache remains valid âœ…

4. Load next thread state (2 Âµs)
   â”œâ”€ Restore CPU registers
   â”œâ”€ Restore program counter
   â””â”€ Resume execution

5. Overhead (1.5 Âµs)
   â””â”€ Context switch logic

Total: ~5 Âµs âœ…

Main benefit: No memory management overhead! âœ…
```

#### B. Performance Calculation

**Scenario: 10,000 context switches/second**
```python
# Constants
switches_per_second = 10_000

# Process context switch
process_switch_time = 50e-6  # 50 microseconds
thread_switch_time = 5e-6    # 5 microseconds

# Calculate CPU time spent on context switching
process_overhead = switches_per_second * process_switch_time
thread_overhead = switches_per_second * thread_switch_time

# Calculate as percentage of CPU time
process_overhead_pct = process_overhead * 100
thread_overhead_pct = thread_overhead * 100

print("CPU time on context switching:")
print(f"Multi-process: {process_overhead:.3f}s = {process_overhead_pct:.1f}%")
print(f"Multi-threaded: {thread_overhead:.3f}s = {thread_overhead_pct:.1f}%")
print(f"Difference: {(process_overhead - thread_overhead):.3f}s")
print(f"Thread is {process_overhead/thread_overhead:.1f}Ã— faster")
```

**Results:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     CONTEXT SWITCHING OVERHEAD (10K/sec)          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                   â•‘
â•‘  Model          â”‚ Time/switch â”‚ Total   â”‚ CPU %  â•‘
â•‘ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â• â•‘
â•‘                                                   â•‘
â•‘  Multi-process  â”‚    50 Âµs    â”‚ 0.50s   â”‚  50%   â•‘
â•‘                 â”‚             â”‚         â”‚  âš ï¸    â•‘
â•‘                                                   â•‘
â•‘  Multi-threaded â”‚     5 Âµs    â”‚ 0.05s   â”‚   5%   â•‘
â•‘                 â”‚             â”‚         â”‚  âœ…    â•‘
â•‘                                                   â•‘
â•‘  Savings        â”‚    45 Âµs    â”‚ 0.45s   â”‚  45%   â•‘
â•‘                 â”‚             â”‚         â”‚  âœ…âœ…  â•‘
â•‘                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Impact on throughput:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Multi-process:
- Available CPU: 50% (rest is context switching)
- Max throughput: 50% of theoretical max âš ï¸

Multi-threaded:
- Available CPU: 95% (only 5% context switching)
- Max throughput: 95% of theoretical max âœ…

Improvement: 1.9Ã— throughput with threads! ğŸš€
```

#### C. Scalability Analysis
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        CONTEXT SWITCH RATE vs OVERHEAD            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                   â•‘
â•‘  Switches/sec â”‚ Process  â”‚ Thread   â”‚ Difference â•‘
â•‘               â”‚ Overhead â”‚ Overhead â”‚            â•‘
â•‘ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â• â•‘
â•‘               â”‚          â”‚          â”‚            â•‘
â•‘     1,000     â”‚    5%    â”‚   0.5%   â”‚    4.5%    â•‘
â•‘    10,000     â”‚   50%    â”‚    5%    â”‚   45% âœ…   â•‘
â•‘   100,000     â”‚  500%â—  â”‚   50%    â”‚  450% âœ…âœ…  â•‘
â•‘ 1,000,000     â”‚ 5000%â—  â”‚  500% âš ï¸ â”‚ 4500%      â•‘
â•‘               â”‚          â”‚          â”‚            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Observations:
- At 10K switches/sec: Process model saturated âŒ
- At 100K switches/sec: Both models unusable
- Thread model scales 10Ã— better âœ…

Recommendation:
- Keep context switches < 10K/sec for processes
- Keep context switches < 100K/sec for threads
```

---

### Pháº§n 3: Multicore Performance

#### A. Multi-Process on Multicore
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      MULTI-PROCESS ON 4-CORE CPU              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘   Core 0      Core 1      Core 2      Core 3 â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ P1   â”‚   â”‚ P2   â”‚   â”‚ P3   â”‚   â”‚ P4   â”‚  â•‘
â•‘  â”‚      â”‚   â”‚      â”‚   â”‚      â”‚   â”‚      â”‚  â•‘
â•‘  â”‚ Own  â”‚   â”‚ Own  â”‚   â”‚ Own  â”‚   â”‚ Own  â”‚  â•‘
â•‘  â”‚ Mem  â”‚   â”‚ Mem  â”‚   â”‚ Mem  â”‚   â”‚ Mem  â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚         SHARED NOTHING                  â”‚ â•‘
â•‘  â”‚  - Each core runs independently        â”‚ â•‘
â•‘  â”‚  - No cache sharing                    â”‚ â•‘
â•‘  â”‚  - No lock contention âœ…               â”‚ â•‘
â•‘  â”‚  - Communication via IPC (slow) âš ï¸     â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Advantages:
âœ… True parallelism (4Ã— throughput)
âœ… No synchronization overhead
âœ… Fault isolation (one crash doesn't affect others)
âœ… Linear scaling (4 cores = 4Ã— performance)

Disadvantages:
âš ï¸ High memory usage (4Ã— memory)
âš ï¸ Slow inter-process communication
âš ï¸ Complex data sharing (requires serialization)
```

#### B. Multi-Threaded on Multicore
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     MULTI-THREADED ON 4-CORE CPU              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘   Core 0      Core 1      Core 2      Core 3 â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ T1   â”‚   â”‚ T2   â”‚   â”‚ T3   â”‚   â”‚ T4   â”‚  â•‘
â•‘  â”‚      â”‚   â”‚      â”‚   â”‚      â”‚   â”‚      â”‚  â•‘
â•‘  â””â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”˜  â•‘
â•‘     â”‚          â”‚          â”‚          â”‚       â•‘
â•‘     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â•‘
â•‘                    â”‚                          â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â•‘
â•‘  â”‚         SHARED MEMORY                    â”‚â•‘
â•‘  â”‚  - Heap (data structures)                â”‚â•‘
â•‘  â”‚  - Global variables                      â”‚â•‘
â•‘  â”‚  - Fast communication âœ…                 â”‚â•‘
â•‘  â”‚  - Need locks (contention) âš ï¸           â”‚â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Advantages:
âœ… Low memory usage (shared heap)
âœ… Fast communication (shared memory)
âœ… Easy data sharing (no serialization)
âœ… Lower overhead per thread

Disadvantages:
âš ï¸ Lock contention (mutex, semaphore)
âš ï¸ Race conditions (hard to debug)
âš ï¸ Cache coherency overhead
âŒ One thread crash kills all threads
```

#### C. Performance Comparison
```python
# Simulation: Process 4 requests on 4 cores

import time

# Multi-process model
def multiprocess_benchmark():
    """
    Each process independent, no synchronization
    """
    processes = 4
    request_time = 100e-3  # 100ms per request
    
    # Parallel execution (no overhead)
    total_time = request_time
    
    # Communication overhead (if needed)
    ipc_overhead = 5e-3 * 3  # 5ms Ã— 3 IPC calls
    
    return total_time + ipc_overhead

# Multi-threaded model
def multithread_benchmark():
    """
    Threads share data, need synchronization
    """
    threads = 4
    request_time = 100e-3
    
    # Parallel execution
    total_time = request_time
    
    # Lock contention overhead
    lock_overhead = 0.5e-3 * 10  # 0.5ms Ã— 10 lock acquisitions
    
    # Cache coherency overhead
    cache_overhead = 1e-3
    
    return total_time + lock_overhead + cache_overhead

# Calculate
mp_time = multiprocess_benchmark()
mt_time = multithread_benchmark()

print(f"Multi-process: {mp_time*1000:.2f}ms")
print(f"Multi-threaded: {mt_time*1000:.2f}ms")
print(f"Winner: {'Thread' if mt_time < mp_time else 'Process'}")
```

**Results:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       4-CORE PERFORMANCE COMPARISON           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  Metric              â”‚ Process â”‚ Thread      â•‘
â•‘ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â• â•‘
â•‘                                               â•‘
â•‘  Request time        â”‚ 100ms   â”‚ 100ms       â•‘
â•‘  IPC overhead        â”‚  15ms   â”‚   0ms âœ…    â•‘
â•‘  Lock overhead       â”‚   0ms   â”‚   5ms âš ï¸    â•‘
â•‘  Cache overhead      â”‚   0ms   â”‚   1ms âš ï¸    â•‘
â•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€á…µâ•‘
â•‘  Total               â”‚ 115ms   â”‚ 106ms âœ…    â•‘
â•‘                                               â•‘
â•‘  Throughput (req/s)  â”‚  34.8   â”‚  37.7 âœ…    â•‘
â•‘  Speedup (vs single) â”‚  3.5Ã—   â”‚  3.8Ã— âœ…    â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Conclusion: Threads slightly faster (8%) âœ…
```

---

### Pháº§n 4: Use Cases

#### A. When to Use Multi-Process
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         USE MULTI-PROCESS WHEN:               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  1. Strong Isolation Required âœ…              â•‘
â•‘     - Untrusted code execution               â•‘
â•‘     - Security-critical applications         â•‘
â•‘     - Example: Web browser tabs              â•‘
â•‘                                               â•‘
â•‘  2. Fault Tolerance Critical âœ…               â•‘
â•‘     - One task failure shouldn't kill others â•‘
â•‘     - Example: Nginx worker processes        â•‘
â•‘                                               â•‘
â•‘  3. Different Programming Languages âœ…        â•‘
â•‘     - Microservices (Python + Go + Java)     â•‘
â•‘     - Example: Service-oriented architecture â•‘
â•‘                                               â•‘
â•‘  4. Independent Tasks âœ…                      â•‘
â•‘     - No/minimal communication needed        â•‘
â•‘     - Example: Video encoding pipeline       â•‘
â•‘                                               â•‘
â•‘  5. Legacy Code Integration âœ…                â•‘
â•‘     - Cannot modify existing processes       â•‘
â•‘     - Example: Enterprise system integration â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Example: Web Server (Nginx)**
```c
// Nginx: Multi-process architecture
void master_process() {
    for (int i = 0; i < num_workers; i++) {
        pid_t pid = fork();
        
        if (pid == 0) {
            // Child process: Worker
            worker_process();
            exit(0);
        }
    }
    
    // Master: Monitor workers
    while (1) {
        pid_t dead_worker = wait(NULL);
        // Restart dead worker
        fork_new_worker();
    }
}

Benefits:
âœ… One worker crash doesn't affect others
âœ… Master can reload config without downtime
âœ… Security: Workers run with low privileges
```

#### B. When to Use Multi-Threaded
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        USE MULTI-THREADED WHEN:               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  1. High Data Sharing âœ…                      â•‘
â•‘     - Frequent communication between tasks   â•‘
â•‘     - Example: Database query engine         â•‘
â•‘                                               â•‘
â•‘  2. Low Latency Required âœ…                   â•‘
â•‘     - Fast context switching needed          â•‘
â•‘     - Example: Real-time trading systems     â•‘
â•‘                                               â•‘
â•‘  3. Memory Constrained âœ…                     â•‘
â•‘     - Limited RAM available                  â•‘
â•‘     - Example: Embedded systems              â•‘
â•‘                                               â•‘
â•‘  4. Many Concurrent Tasks âœ…                  â•‘
â•‘     - Thousands of simultaneous requests     â•‘
â•‘     - Example: Web server (Apache)           â•‘
â•‘                                               â•‘
â•‘  5. Shared State Required âœ…                  â•‘
â•‘     - Global data structures                 â•‘
â•‘     - Example: In-memory cache (Redis)       â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Example: Web Server (Apache)**
```java
// Apache: Multi-threaded worker
class ApacheWorker extends Thread {
    private ConnectionPool pool;
    private Cache cache;  // Shared!
    
    public void run() {
        while (true) {
            Request req = pool.accept();
            
            // Check shared cache (fast!)
            if (cache.has(req.url)) {
                send(cache.get(req.url));
            } else {
                Response res = processRequest(req);
                cache.put(req.url, res);
                send(res);
            }
        }
    }
}

Benefits:
âœ… All threads share cache (memory efficient)
âœ… Fast communication (shared memory)
âœ… Low overhead (5Âµs context switch)
```

#### C. Hybrid Approach
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          HYBRID: BEST OF BOTH WORLDS          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘   Master Process                              â•‘
â•‘         â”‚                                     â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”                  â•‘
â•‘   â”‚     â”‚     â”‚     â”‚     â”‚                   â•‘
â•‘   P1    P2    P3    P4    P5 (Worker procs)  â•‘
â•‘   â”‚     â”‚     â”‚     â”‚     â”‚                   â•‘
â•‘  â”Œâ”´â”   â”Œâ”´â”   â”Œâ”´â”   â”Œâ”´â”   â”Œâ”´â”                 â•‘
â•‘  â”‚T1   â”‚T1   â”‚T1   â”‚T1   â”‚T1                 â•‘
â•‘  â”‚T2   â”‚T2   â”‚T2   â”‚T2   â”‚T2  (Threads)      â•‘
â•‘  â”‚T3   â”‚T3   â”‚T3   â”‚T3   â”‚T3                 â•‘
â•‘  â””â”€â”˜   â””â”€â”˜   â””â”€â”˜   â””â”€â”˜   â””â”€â”˜                 â•‘
â•‘                                               â•‘
â•‘  Benefits:                                    â•‘
â•‘  âœ… Fault isolation (between processes)      â•‘
â•‘  âœ… Fast communication (within process)      â•‘
â•‘  âœ… Scalability (threads) + Stability (procs)â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Examples:
- Chrome: Multi-process (tabs) + multi-thread (rendering)
- PostgreSQL: Multi-process (connections) + worker threads
- Node.js Cluster: Multi-process + event loop
```

---

## ğŸ“Š TÃ³m táº¯t

### Key Points

- âœ… **Process**: Isolated memory, 50Âµs context switch, fault-tolerant
- âœ… **Thread**: Shared memory, 5Âµs context switch, fast communication
- âœ… **Context switch overhead**: Thread 10Ã— faster than process
- âœ… **10K switches/sec**: 50% CPU (process) vs 5% CPU (thread)
- âœ… **Multicore**: Both scale linearly, threads slightly faster

### Decision Matrix
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           WHEN TO USE WHICH MODEL             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                               â•‘
â•‘  Requirement        â”‚ Multi-Process â”‚ Thread â•‘
â•‘ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â• â•‘
â•‘                                               â•‘
â•‘  Fault isolation    â”‚      âœ…       â”‚   âŒ   â•‘
â•‘  Fast communication â”‚      âŒ       â”‚   âœ…   â•‘
â•‘  Low memory usage   â”‚      âŒ       â”‚   âœ…   â•‘
â•‘  Security           â”‚      âœ…       â”‚   âš ï¸   â•‘
â•‘  Low latency        â”‚      âŒ       â”‚   âœ…   â•‘
â•‘  Scalability        â”‚      âš ï¸       â”‚   âœ…   â•‘
â•‘  Debugging ease     â”‚      âœ…       â”‚   âŒ   â•‘
â•‘                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Recommendations

| Scenario | Choice | Reason |
|----------|--------|--------|
| Web server (high traffic) | **Thread** âœ… | Low overhead, shared cache |
| Microservices | **Process** âœ… | Isolation, different languages |
| Real-time system | **Thread** âœ… | Low latency (5Âµs switch) |
| Batch processing | **Process** âœ… | Independent tasks |
| In-memory database | **Thread** âœ… | Shared data structures |
| Critical infrastructure | **Hybrid** âœ… | Best of both worlds |

---

## ğŸ”— TÃ i liá»‡u tham kháº£o

### Books
- **Operating System Concepts** - Silberschatz (Chapter 4)
- **Modern Operating Systems** - Tanenbaum (Chapter 2)

### Papers
- **Scheduler Activations** - Anderson et al., 1991
- **The Performance of Âµ-Kernel-Based Systems** - Liedtke, 1995

---

## ğŸ§­ Navigation

**[â¬…ï¸ ChÆ°Æ¡ng 2](../chuong-2/README.md)** | **[ğŸ“š Quay láº¡i ChÆ°Æ¡ng 3](./README.md)** | **[â¡ï¸ CÃ¢u 2: Thread Models](./cau-2-thread-models.md)**

---

*Cáº­p nháº­t láº§n cuá»‘i: 11/12/2025*